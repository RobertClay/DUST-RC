% !TEX root = ParticleFilter.tex
\section{Introduction\label{introduction}}

Agent-based modelling is a form of computer simulation that is well suited to modelling human systems~\citep{bonabeau_agent_2002,  farmer_economy_2009}. In recent years it has emerged as an important tool for decision makers who need to base their decisions on the behaviour of crowds of people~\citep{henein_agentbased_2005}. Such models, that simulate the behaviour of synthetic individual people (`agents'), have been proven to be useful as tools to experiment with strategies for humanitarian assistance \citep{crooks_gis_2013}, emergency evacuations \citep{ren_agentbased_2009, schoenharl_design_2011}, religious festivals~\citep{zainuddin_simulating_2009}, crowd stampedes~\citep{helbing_simulating_2000} etc. Although many agent-based crowd simulations have been developed, there is a fundamental methodological difficulty that modellers face: there are no established mechanisms for incorporating real-time data into simulations \citep{lloyd_exploring_2016, wang_data_2015, ward_dynamic_2016}. Models are typically calibrated once, using historical data, and then projected forward in time to make a prediction independently of any new data that might arise. Although this makes them effective at analysing scenarios to create information that can be useful in the design of crowd management policies, it means that they cannot currently be used to simulate real crowd systems \textit{in real time}. Without knowledge of the current state of a system it is difficult to decide on the most appropriate management plan for emerging situations.

Fortunately, methods do exist to reliably incorporate emerging data into models. \textit{Data assimilation} (DA) is a technique that has been widely used in fields such as meteorology, hydrology and oceanography, and is one of the main reasons that weather forecasts have improved so substantially in recent decades \citep{kalnay_atmospheric_2003}. Broadly, DA refers to a suite of techniques that allow observational data from the real world to be incorporated into models \citep{lewis_dynamic_2006}. This makes it possible to more accurately represent the current state of the system, and therefore reduce the uncertainty in future predictions.

It is important to note the differences between the data assimilation approach used here and that of typical agent-based parameter estimation / calibration. The field of optimisation -- finding suitable estimates for the parameters of algorithms -- has (and continues to be) an extremely well-researched field that agent-based modellers often draw on. For example, agent-based models regularly make use of sampling methods, such as Latin Hypercube sampling \citep{thiele_facilitating_2014} or evolutionary / heuristic optimisation algorithms such as simulated annealing~\citep{pennisi_optimal_2008}, genetic algorithms,~\citep{heppenstall_genetic_2007}, and approximate Bayesian computation~\citep{grazzini_bayesian_2017}. There are also new software tools becoming available to support advanced parameter exploration \citep{ozik_extremescale_2018}. It is, however, worth noting that in most cases agent-based models are not calibrated to quantitative data~\citep{thiele_facilitating_2014}.  In the cases where parameter estimation does take place, it is typically performed as a single calibration step in a waterfall-style development process -- e.g. design, implementation, calibration, validation. Although there are some more recent studies that do attempt to re-calibrate model parameters dynamically during runtime \citep[e.g.][]{oloo_adaptive_2017a, oloo_predicting_2018} there is another, more fundamental, difference to typical parameter optimisation (be it static or dynamic) and the data assimilation approach. 

Even if optimal model parameters have been found, there will usually be a degree of uncertainty in the model. With crowd simulations, for example, it is impossible to know \textit{exactly} how individuals will behave in a given situation -- will someone turn left or right given two competing options? -- nor can individual parameters such as walking speed ever be known exactly. Data assimilation algorithms use `state estimation' to calculate the difference between the model and the `true' state of the underlying system at runtime. They are then able to adjust the current model state in order to constrain a model's continued evolution against the real world~\citep{ward_dynamic_2016}. Although it is possible to re-calibrate models dynamically during runtime (e.g. \citep{oloo_adaptive_2017a}), this would not reduce the natural uncertainty that arises as stochastic models evolve. 

This paper is part of a wider programme of work\footnote{\url{http://dust.leeds.ac.uk/}} whose main aim is to develop data assimilation methods that can be used in agent-based modelling. The software codes that underpin the work discussed here are available in full from the project code repository; see Appendix~\ref{appendix:code}. The work here focuses on one particular system -- that of pedestrian movements -- and one particular method -- the particle filter. A particle filter is a brute force Bayesian state estimation method whose goal is to estimate the `true' state of a system, obtained by combining a model estimate with observational data, using an ensemble of model instances called particles. When observational data become available, the algorithm identifies those model instances (particles) whose state is closest to that of the observational data, and then re-samples particles based on this distance. It is worth noting that once an accurate estimate of the \textit{current} state of the system has been calculated, predictions of future states should be much more reliable -- c.f. the substantial improvements in weather forecasting that have come about as a result of modern data assimilation methods~\citep{kalnay_atmospheric_2003}. Predicting future system states is beyond the scope of this paper however.

The overall aim of the paper is to: \begin{quote}\textit{\aim}.\end{quote} This will be achieved through a number of experiments following an `identical twin' approach \citep{wang_data_2015}. The agent-based model is first executed to produce hypothetical real data -- also known as pseudo-truth \citep{grazzini_bayesian_2017} data -- and these data are assumed to be drawn from the real world. During data assimilation, observations are derived from the pseudo-truth data. This approach has the advantage that the `true' system state can be known precisely, and so the accuracy of the particle filter can be calculated. In reality, the true system state can never be known.

The agent-based model under study is designed to represent a very simple pedestrian system. It has been kept intentionally simple because the aim here is to experiment with the particle filter, not to accurately simulate a pedestrian system. Were the model more complicated it would become more difficult to understand the internal uncertainties, which would in turn make it more difficult to understand how well the particle filter was able to handle these uncertainties. The model is sufficiently complex to allow the emergence of crowding, so its dynamics could not be easily replicated by a simpler mathematical model -- as per \citep{lloyd_exploring_2016} and \citep{ward_dynamic_2016} -- but is otherwise as simple as possible. Crowding occurs because the agents have a variable maximum speed, therefore slower agents hold up faster ones who are behind them. The only uncertainty in the model, which the particle filter is tasked with managing, occurs when a faster agent must make a random choice whether to move round a slower agent to the left or right. Without that uncertain behaviour the model would be deterministic. A more realistic crowd simulation \citep[e.g.][]{helbing_simulating_2000} would exhibit much more complicated behavioural dynamics.

The paper is outlined as follows: Section~\ref{background} reviews the relevant literature; Section~\ref{method} outlines the methods, including a description of the agent based model and particle filter; Section~\ref{experiments} outlines the experiments that are conducted and their results; and Section~\ref{discussion} draws conclusions and outlines opportunities for future work.
