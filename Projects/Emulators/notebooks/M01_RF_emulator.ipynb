{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This note book implements Random Forest emulator for the data from StationSim\n",
    "The data must be located in the data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "import matplotlib.pyplot as plt\n",
    "#from gp_emulator import GaussianProcess\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sys import path\n",
    "path.append('..')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the trained model\n",
    "def evaluate(dats, model, scaler, predictsteps, lookbacksteps):\n",
    "    train_X = dats[0]\n",
    "    train_y = dats[1]\n",
    "    test_X = dats[2]\n",
    "    test_y = dats[3]\n",
    "\n",
    "    yhat = model.predict(test_X)\n",
    "    #print(yhat)\n",
    "    # Rescale values back to the original values\n",
    "    #test_rescpred=scaler.inverse_transform(yhat)\n",
    "    #test_rescref=scaler.inverse_transform(test_y)\n",
    "\n",
    "    test_rescpred=yhat\n",
    "    test_rescref=test_y\n",
    "    #print(test_X)\n",
    "\n",
    "    ## Performance measures\n",
    "    #seg_mael=[] #MAE list over detectors\n",
    "\n",
    "    #for j in range(train_X.shape[-1]):\n",
    "        \n",
    "    #    seg_mael.append(np.mean(np.abs(test_rescref.T[j]-test_rescpred.T[j]))) #Mean Absolute Error\n",
    "    \n",
    "    #return (np.array(seg_mael), test_rescpred, test_rescref)\n",
    "    return (test_rescpred, test_rescref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the training data for the prediction model\n",
    "def prepare_data(datatrain, datatest, time_train, time_test, sensor=1, pred=1, lb=1):\n",
    "    train_dat = np.array(datatrain)\n",
    "    train_dat = np.nan_to_num(train_dat)\n",
    "    test_dat = np.array(datatest)\n",
    "    test_dat = np.nan_to_num(test_dat)\n",
    "    predictsteps = pred\n",
    "    lookbacksteps = lb\n",
    "    whichsensor = sensor\n",
    "\n",
    "    #Scale on training data (fit and transform)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_dat = train_dat.astype('float32')\n",
    "    train_scaled = scaler.fit_transform(train_dat)\n",
    "    test_scaled = scaler.transform(test_dat)\n",
    "    \n",
    "    train_scaled = train_dat\n",
    "    test_scaled = test_dat\n",
    "    \n",
    "    train_X=[]\n",
    "    train_y=[]\n",
    "    test_X=[]\n",
    "    test_y=[]\n",
    "    \n",
    "    #prepare the training dataset\n",
    "    for j in range(len(train_scaled)-int(predictsteps+lookbacksteps-1)):\n",
    "        if (time_train[j]<=lb) or (time_train[int(predictsteps+lookbacksteps-1)+j]<lb):\n",
    "            continue\n",
    "\n",
    "        train_datset=train_scaled[j:lookbacksteps+j,2:]\n",
    "        train_ycomp=train_scaled[int(predictsteps+lookbacksteps-1)+j,whichsensor+2]\n",
    "        #print(train_ycomp)\n",
    "        train_X.append(train_datset)\n",
    "        train_y.append(train_ycomp)\n",
    "        \n",
    "    #prepare the testing dataset\n",
    "    for j in range(len(test_scaled)-int(predictsteps+lookbacksteps-1)):\n",
    "        if (time_test[j]<=lb) or (time_test[int(predictsteps+lookbacksteps-1)+j]<lb):\n",
    "            continue\n",
    "\n",
    "        test_datset=test_scaled[j:lookbacksteps+j,2:]\n",
    "        test_ycomp=test_scaled[int(predictsteps+lookbacksteps-1)+j,whichsensor+2]\n",
    "        #print(test_ycomp)\n",
    "        test_X.append(test_datset)\n",
    "        test_y.append(test_ycomp)\n",
    "    \n",
    "    train_X = np.squeeze(np.array(train_X))\n",
    "    train_y = np.array(train_y)\n",
    "    test_X = np.squeeze(np.array(test_X))\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.transform(test_X)\n",
    "\n",
    "    return (train_X, train_y, test_X, test_y, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now this is the function to train the Random Forest\n",
    "def train_rf(train_X, train_y, test_X, test_y, scaler, pred, lb):\n",
    "    #Model creation\n",
    "\n",
    "    #now train a new RF model\n",
    "    regressor = RandomForestRegressor(n_estimators=10, random_state=123)\n",
    "    regressor.fit(train_X, train_y)\n",
    "\n",
    "    #Evaluate\n",
    "    dats=(train_X, train_y, test_X, test_y)\n",
    "    test_rescpred, test_rescref = evaluate(dats, regressor, scaler, pred, lb)\n",
    "    #print('Model MAE: '+str(np.mean(mael)))\n",
    "    \n",
    "    return (test_rescpred, test_rescref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's try the case where we know the demand (number of pedestrian) in advance\n",
    "\n",
    "### Scenario 1: If we know the number of pedestrian in advance, the uncertainty only comes from the fact that StationSim is stochastic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:  2\n",
      "Step ahead:  5\n",
      "Step ahead:  10\n",
      "Step ahead:  15\n"
     ]
    }
   ],
   "source": [
    "#we make a loop to predict each value in the testing data\n",
    "\n",
    "for k in [2]:\n",
    "#for k in range(1,6):\n",
    "    print(\"Test data: \", k)\n",
    "    df_train = pd.read_csv('../data/raw/df_pop_'+str(k)+'00_v6.csv')\n",
    "    time_train = df_train['# Time']\n",
    "    df_train = df_train.drop(['# Time'], axis=1)\n",
    "    df_test = pd.read_csv('../data/validate/df_pop_'+str(k)+'00_test_v6.csv')\n",
    "    time_test = df_test['# Time']\n",
    "    df_test = df_test.drop(['# Time'], axis=1)\n",
    "    #df_test\n",
    "    datatrain = df_train.values\n",
    "    datatest = df_test.values\n",
    "    #predict each step ahead\n",
    "    for m in [5,10,15]:\n",
    "    #for m in [1]:\n",
    "        print(\"Step ahead: \", m)\n",
    "        test_values = []\n",
    "        pred_values = []\n",
    "        for sensor in range(10):\n",
    "            #print(\"Sensor: \", sensor)\n",
    "            train_X, train_y, test_X, test_y, scaler = prepare_data(datatrain, datatest, time_train, time_test,sensor, m, 1)\n",
    "            test_rescpred, test_rescref=train_rf(train_X, train_y, test_X, test_y, scaler, m, 5)\n",
    "            test_values.append(test_rescref)\n",
    "            pred_values.append(test_rescpred)\n",
    "        \n",
    "        #now predict the delay\n",
    "        train_X, train_y, test_X, test_y, scaler = prepare_data(datatrain, datatest, time_train, time_test,-2, m, 1)\n",
    "        #print(test_y)\n",
    "        test_rescpred, test_rescref=train_rf(train_X, train_y, test_X, test_y, scaler, m, 1)\n",
    "        test_values.append(test_rescref)\n",
    "        pred_values.append(test_rescpred)\n",
    "        #now compbine the data into data frames\n",
    "        test_values = pd.DataFrame(test_values)\n",
    "        pred_values = pd.DataFrame(pred_values)\n",
    "        #transpose and save CSV    \n",
    "        test_values=test_values.T\n",
    "        pred_values=pred_values.T\n",
    "        \n",
    "        pred_values.to_csv(\"../outputs/RF/Test_pop\"+str(k)+\"00_predict_SH\"+str(m)+\"_RF.csv\")\n",
    "        test_values.to_csv(\"../outputs/RF/Test_pop\"+str(k)+\"00_real_SH\"+str(m)+\"_RF.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2\n",
      "0  18.210421  20.815306  21.021167\n",
      "1  22.093419  20.716777  21.530060\n",
      "2  23.053329  23.588711  23.833653\n",
      "3  21.374608  23.029229  25.363711\n",
      "4  24.055510  26.323399  29.512223\n",
      "           0          1          2\n",
      "0  24.989606  28.546197  29.112638\n",
      "1  29.396776  27.784768  28.813802\n",
      "2  30.361993  29.893897  30.447684\n",
      "3  29.718542  31.551706  36.165958\n",
      "4  33.605209  37.691516  46.217295\n"
     ]
    }
   ],
   "source": [
    "#Calculate MAE and RMSE\n",
    "#Each population training and testing RF\n",
    "from math import sqrt\n",
    "columns = [0, 1, 2]\n",
    "maes = pd.DataFrame(columns=columns)\n",
    "rmses = pd.DataFrame(columns=columns)\n",
    "for k in range(1,6):\n",
    "    #print(\"Evalue data: \", k)\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    for m in [5,10,15]:\n",
    "        #print(\"Step ahead: \", m)\n",
    "        predicts = pd.read_csv(\"../outputs/RF/Test_pop\"+str(k)+\"00_predict_SH\"+str(m)+\"_RF.csv\")\n",
    "        reals = pd.read_csv(\"../outputs/RF/Test_pop\"+str(k)+\"00_real_SH\"+str(m)+\"_RF.csv\")\n",
    "        #print(mean_absolute_error(predicts[0].values, reals[0].values))\n",
    "        mae.append(mean_absolute_error(predicts['10'].values, reals['10'].values))\n",
    "        rmse.append(sqrt(mean_squared_error(predicts['10'].values, reals['10'].values)))\n",
    "    mae = pd.Series(mae)\n",
    "    #print(mae)\n",
    "    mae = pd.DataFrame([mae])\n",
    "    #print(mae)\n",
    "    rmse = pd.Series(rmse)\n",
    "    rmse = pd.DataFrame([rmse])\n",
    "    maes = pd.concat([maes, mae], ignore_index=True)\n",
    "    rmses = pd.concat([rmses, rmse], ignore_index=True)\n",
    "print(maes)\n",
    "print(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: We don't know the number of pedestrians in advance, so we feed the model all the data that we have, and then at the testing phase we see if the model can generalise, now the uncertainty also comes from the fact that the number of pedestrian is unknown to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:  1\n",
      "Step ahead:  5\n",
      "Step ahead:  10\n",
      "Step ahead:  15\n",
      "Test data:  2\n",
      "Step ahead:  5\n",
      "Step ahead:  10\n",
      "Step ahead:  15\n",
      "Test data:  3\n",
      "Step ahead:  5\n",
      "Step ahead:  10\n",
      "Step ahead:  15\n",
      "Test data:  4\n",
      "Step ahead:  5\n",
      "Step ahead:  10\n",
      "Step ahead:  15\n",
      "Test data:  5\n",
      "Step ahead:  5\n",
      "Step ahead:  10\n",
      "Step ahead:  15\n"
     ]
    }
   ],
   "source": [
    "##### train and test on all dataset\n",
    "train_files = ['../data/raw/df_pop_'+str(i)+'00_v5.csv' for i in range(1,6)]\n",
    "df_train = pd.concat([pd.read_csv(f) for f in train_files], ignore_index = True)\n",
    "\n",
    "time_train = df_train['# Time']\n",
    "#print(time_train[5])\n",
    "df_train = df_train.drop(['# Time'], axis=1)\n",
    "datatrain = df_train.values\n",
    "    \n",
    "for k in range(1,6):\n",
    "    print(\"Test data: \", k)\n",
    "    df_test = pd.read_csv('../data/validate/df_pop_'+str(k)+'00_test_v5.csv')\n",
    "    time_test = df_test['# Time']\n",
    "    df_test = df_test.drop(['# Time'], axis=1)\n",
    "    #df_test\n",
    "    datatest = df_test.values\n",
    "\n",
    "    for m in [5,10,15]:\n",
    "    #for m in [1]:\n",
    "        print(\"Step ahead: \", m)\n",
    "        test_values = []\n",
    "        pred_values = []\n",
    "        for sensor in range(10):\n",
    "            #print(\"Sensor: \", sensor)\n",
    "            train_X, train_y, test_X, test_y, scaler = prepare_data(datatrain, datatest, time_train, time_test,sensor, m, 1)\n",
    "            test_rescpred, test_rescref=train_rf(train_X, train_y, test_X, test_y, scaler, m, 5)\n",
    "            test_values.append(test_rescref)\n",
    "            pred_values.append(test_rescpred)\n",
    "        \n",
    "        #now predict the delay\n",
    "        train_X, train_y, test_X, test_y, scaler = prepare_data(datatrain, datatest, time_train, time_test,-2, m, 1)\n",
    "        #print(test_y)\n",
    "        test_rescpred, test_rescref=train_rf(train_X, train_y, test_X, test_y, scaler, m, 5)\n",
    "        test_values.append(test_rescref)\n",
    "        pred_values.append(test_rescpred)\n",
    "        #now compbine the data into data frames\n",
    "        test_values = pd.DataFrame(test_values)\n",
    "        pred_values = pd.DataFrame(pred_values)\n",
    "        #transpose and save CSV    \n",
    "        test_values=test_values.T\n",
    "        pred_values=pred_values.T\n",
    "        \n",
    "        pred_values.to_csv(\"../outputs/RF/All_pop\"+str(k)+\"00_predict_SH\"+str(m)+\"_RF.csv\")\n",
    "        test_values.to_csv(\"../outputs/RF/All_pop\"+str(k)+\"00_real_SH\"+str(m)+\"_RF.csv\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2\n",
      "0  23.575534  23.497798  25.136978\n",
      "1  29.127502  29.586836  30.426127\n",
      "2  26.679158  25.999978  26.695012\n",
      "3  21.249163  23.607179  24.948411\n",
      "4  32.303084  35.378768  32.846348\n",
      "           0          1          2\n",
      "0  31.524104  31.554889  34.404714\n",
      "1  38.183606  38.712708  39.376664\n",
      "2  35.259028  33.784200  35.356813\n",
      "3  29.019660  32.052200  34.243569\n",
      "4  42.671798  45.580251  43.547064\n"
     ]
    }
   ],
   "source": [
    "#Calculate MAE and RMSE\n",
    "#Each population training and testing RF\n",
    "from math import sqrt\n",
    "columns = [0, 1, 2]\n",
    "maes = pd.DataFrame(columns=columns)\n",
    "rmses = pd.DataFrame(columns=columns)\n",
    "for k in range(1,6):\n",
    "    #print(\"Evalue data: \", k)\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    for m in [5,10,15]:\n",
    "        #print(\"Step ahead: \", m)\n",
    "        predicts = pd.read_csv(\"../outputs/RF/All_pop\"+str(k)+\"00_predict_SH\"+str(m)+\"_RF.csv\")\n",
    "        reals = pd.read_csv(\"../outputs/RF/All_pop\"+str(k)+\"00_real_SH\"+str(m)+\"_RF.csv\")\n",
    "        #print(mean_absolute_error(predicts[0].values, reals[0].values))\n",
    "        mae.append(mean_absolute_error(predicts['10'].values, reals['10'].values))\n",
    "        rmse.append(sqrt(mean_squared_error(predicts['10'].values, reals['10'].values)))\n",
    "    mae = pd.Series(mae)\n",
    "    #print(mae)\n",
    "    mae = pd.DataFrame([mae])\n",
    "    #print(mae)\n",
    "    rmse = pd.Series(rmse)\n",
    "    rmse = pd.DataFrame([rmse])\n",
    "    maes = pd.concat([maes, mae], ignore_index=True)\n",
    "    rmses = pd.concat([rmses, rmse], ignore_index=True)\n",
    "print(maes)\n",
    "print(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
