{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Filter using external data\n",
    "    author: P. Ternes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this text we track changes made in the Particle Filter code to perform data assimilation using external data. After explaining the changes made to the code, an experiment with particle filter using external data is presented.\n",
    "\n",
    "The particle filter **code** that uses external data can be obtained [`here`](../../stationsim/particle_filter_gcs.py).\n",
    "\n",
    "A **notebook** with more information about the Particle Filter can be found [`here`](../pf_experiments/pf_experiments_plots.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary files\n",
    "\n",
    "This version of the particle filter uses data external to the code. For this code to work correctly, it is necessary to standardize the external data according to the instructions below.\n",
    "* create a folder to store the external data;\n",
    "* create a file named <b>activation.dat</b> inside this folder;\n",
    "* create <b>N</b> files named <b>frame_i.dat</b> inside this folder, where i varies from 1 to the N (maximum number of frames observed);\n",
    "\n",
    "Below you will find a detailed description of how each of these files should be organized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation.dat file\n",
    "\n",
    "The activation.dat file contains information about the pedestrian. The informations are:\n",
    "* <b>pedestrianID:</b> one unique ID that identifies the pedestrian. Integer number;\n",
    "* <b>time_activation:</b> the time that each pedestrian enters the environment through any gate. Real number;\n",
    "* <b>gate_in:</b> the gate ID through which the pedestrian enters the environment. Integer number;\n",
    "* <b>gate_out:</b> the gate ID through which the pedestrian leaves the environment. Integer number;\n",
    "* <b>speed:</b> the average speed of the pedestrian. Real number;\n",
    "\n",
    "The first line of the file is a comment line beginning with <b>#</b> and followed by the header.\n",
    "The following lines contain the information listed above, separated only by space and in the sequence mentioned. If you do not have some information, you must keep a specific column with <i>None</i>.\n",
    "\n",
    "The file must have the structure represented below:\n",
    "\n",
    "\n",
    "|# pedestrianID | time_activation | gate_in | gate_out | speed  |\n",
    "|:--------------|:----------------|:--------|:---------|:-------|\n",
    "|0              |24.33457         |6        |2         |1.7377  |\n",
    "|1              |13.3245          |8        |4         |0.31979 |\n",
    "|$\\vdots$       |$\\vdots$         |$\\vdots$ |$\\vdots$  |$\\vdots$|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_i.dat\n",
    "\n",
    "The frame_i.dat file contains information about each active pedestrian's position in the i-th frame. The informations are:\n",
    "* <b>pedestrianID:</b> one unique ID that identifies the pedestrian. The same ID used in the activation.dat file. Integer number;\n",
    "* <b>x:</b> the pedestrian's $x$ position in the i-th frame. Real number;\n",
    "* <b>y:</b> the pedestrian's $y$ position in the i-th frame. Real number;\n",
    "\n",
    "The first line of the file is a comment line beginning with <b>#</b> and followed by the header.\n",
    "The following lines contain the information listed above, separated only by space and in the sequence mentioned. Only active pedestrian are listed in each frame_i.dat file. If there is no active pedestrian in the i-th frame, save the file with the header comment only.\n",
    "\n",
    "The file must have the structure represented below:\n",
    "\n",
    "| #pedestrianID | x       | y      |\n",
    "|:--------------|:--------|:-------|\n",
    "|55             |198.872  |124.2976|\n",
    "|58             |168.27   |13.1725 |\n",
    "|$\\vdots$       |$\\vdots$ |$\\vdots$|\n",
    "\n",
    "As data assimilation is not carried out over the entire time step, it is not necessary to create files for all frames. The files really needed are the frames where data assimilation occurs and are related to the parameter <b>resample_window</b>. For example, if resample_window = 100, it is necessary the files: frame_100.dat, frame_200.dat, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation\n",
    "\n",
    "To use external data is necessary pass to the particle filter a parameter with the key <b>'external_data'</b> and the value <b><i>True</i></b>. It is also necessary to fill <b>'external_info'</b> list with the data directory and <b><i>booleans</i></b> for the use of speed and the exit gate (in this order).\n",
    "\n",
    "the E.g. like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'external_data': True,\n",
    "               'external_info': ['external_data_dir/', True, True] #[data dir, Use external velocit?, Use external gate_out?]\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use pseudo-truth data, pass the value <i>False</i> for the key <i>'external_data'</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial conditions\n",
    "\n",
    "After create the base_model object inside the particle filter it is necessary to give the desired initial condition for each agent. To do that, we create the <b>set_initial_conditions()</b> method, that uses the <b>external_data_dir/activation.dat</b> file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_conditions(self):\n",
    "    '''\n",
    "     To use external file to determine some agents parameters values;\n",
    "     self.external_info[0]: directory name\n",
    "     self.external_info[1]: boolean to use speed\n",
    "     self.external_info[2]: boolean to use gate_out\n",
    "    '''\n",
    "    \n",
    "    file_name = self.external_info[0] + 'activation.dat'\n",
    "    ID, time, gateIn, gateOut, speed_ = np.loadtxt(file_name,unpack=True)\n",
    "    for i in range(self.base_model.pop_total):\n",
    "        self.base_model.agents[i].steps_activate = time[i]\n",
    "        self.estimate_model.agents[i].step_start = time[i]\n",
    "        self.base_model.agents[i].gate_in = int(gateIn[i])\n",
    "        for model in self.models:\n",
    "            model.agents[i].steps_activate = time[i]\n",
    "            model.agents[i].gate_in = int(gateIn[i])\n",
    "        if self.external_info[1]:\n",
    "            self.base_model.agents[i].speed = speed_[i]\n",
    "            for model in self.models:\n",
    "                model.agents[i].speed = speed_[i]\n",
    "        if self.external_info[2]:\n",
    "            self.base_model.agents[i].loc_desire = self.base_model.agents[i].set_agent_location(int(gateOut[i]))\n",
    "            for model in self.models:\n",
    "                model.agents[i].loc_desire = self.base_model.agents[i].loc_desire\n",
    "\n",
    "    '''\n",
    "     If the speed is not obteined from external data, generate new speeds\n",
    "     for all agents in all particles.\n",
    "    '''\n",
    "    if not self.external_info[1]:\n",
    "        for model in self.models:\n",
    "            for agent in model.agents:\n",
    "                speed_max = 0\n",
    "                while speed_max <= model.speed_min:\n",
    "                    speed_max = np.random.normal(model.speed_mean, model.speed_std)\n",
    "                agent.speeds = np.arange(speed_max, model.speed_min, - model.speed_step)\n",
    "                agent.speed = np.random.choice((agent.speeds))\n",
    "\n",
    "    '''\n",
    "     If the gate_out is not obteined from external data, generate new \n",
    "     gate_out for all agents in all particles.\n",
    "    '''\n",
    "    if not self.external_info[2]:\n",
    "        for model in self.models:\n",
    "            for agent in model.agents:\n",
    "                agent.set_gate_out()\n",
    "                agent.loc_desire = agent.set_agent_location(agent.gate_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "In the <b>predict</b> method the particles state are determined. \n",
    "\n",
    "In this method is also determined the state of the base_model object. To use external data, this method has been rewritten:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, numiter=1):\n",
    "    '''\n",
    "    Predict\n",
    "\n",
    "    DESCRIPTION\n",
    "    Increment time. Step the base model. Use a multiprocessing method to step\n",
    "    particle models, set the particle states as the agent\n",
    "    locations with some added noise, and reassign the\n",
    "    locations of the particle agents using the new particle\n",
    "    states. We extract the models and states from the stepped\n",
    "    particles variable.\n",
    "\n",
    "    :param numiter: The number of iterations to step (usually either 1, or the  resample window\n",
    "    '''\n",
    "\n",
    "    time = self.time - numiter\n",
    "\n",
    "    if self.do_external_data:\n",
    "        for i in range(numiter):\n",
    "            time = time + 1\n",
    "            file_name = self.external_info[0] + 'frame_' + str(time)+ '.0.dat'\n",
    "            try:\n",
    "                agentID, x, y = np.loadtxt(file_name,unpack=True)\n",
    "                j = 0\n",
    "                for agent in self.base_model.agents:\n",
    "                    if (agent.unique_id in agentID):\n",
    "\n",
    "                        agent.status = 1\n",
    "                        agent.location = [x[j], y[j]]\n",
    "                        j += 1\n",
    "                    elif (agent.status == 1):\n",
    "                        agent.status = 2\n",
    "            except TypeError:\n",
    "                '''\n",
    "                This error occurs when only one agent is active. In\n",
    "                this case, the data is read as a float instead of an\n",
    "                array.\n",
    "                '''\n",
    "                for agent in self.base_model.agents:\n",
    "                    if (agent.unique_id == agentID):\n",
    "                        agent.status = 1\n",
    "                        agent.location = [x, y]\n",
    "                    elif (agent.status == 1):\n",
    "                        agent.status = 2\n",
    "            except ValueError:\n",
    "                '''\n",
    "                 This error occurs when there is no active agent in\n",
    "                 the frame.\n",
    "                 - Deactivate all active agents.\n",
    "                '''\n",
    "                for agent in self.base_model.agents:\n",
    "                    if (agent.status == 1):\n",
    "                        agent.status = 2\n",
    "\n",
    "            except OSError:\n",
    "                '''\n",
    "                This error occurs when there is no external file to\n",
    "                read. It should only occur at the end of the simulation.\n",
    "                - Deactivate all agent.\n",
    "                '''\n",
    "                for agent in self.base_model.agents:\n",
    "                    agent.status = 2\n",
    "\n",
    "    else:\n",
    "        for i in range(numiter):\n",
    "            self.base_model.step()\n",
    "\n",
    "    stepped_particles = self.pool.starmap(ParticleFilter.step_particle, list(zip( \\\n",
    "        range(self.number_of_particles),  # Particle numbers (in integer)\n",
    "        [m for m in self.models],  # Associated Models (a Model object)\n",
    "        [numiter] * self.number_of_particles,  # Number of iterations to step each particle (an integer)\n",
    "        [self.particle_std] * self.number_of_particles,  # Particle std (for adding noise) (a float)\n",
    "        [s.shape for s in self.states],  # Shape (for adding noise) (a tuple)\n",
    "    )))\n",
    "\n",
    "    self.models = [stepped_particles[i][0] for i in range(len(stepped_particles))]\n",
    "    self.states = np.array([stepped_particles[i][1] for i in range(len(stepped_particles))])\n",
    "    self.get_state_estimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning!\n",
    "Note that there is different exceptions for the files reading. This is usefull since we need to read files with different shapes. The drawback of this approach is that if the files are not organized in the correct way, the code will not report a possible error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Below, some instructions and experiments using external data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialization\n",
    "\n",
    "Determine the path for the model and the filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../stationsim')\n",
    "from particle_filter_gcs import ParticleFilter\n",
    "from stationsim_gcs_model import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters necessary to initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'pop_total': 274,\n",
    "                'batch_iterations': 3100,\n",
    "                'step_limit': 3100,\n",
    "                'birth_rate': 25./15,\n",
    "                'do_history': False,\n",
    "                'do_print': False,\n",
    "                'station': 'Grand_Central'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters necessary to initialize the Particle Filter. Different experiments have different sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_params = {'number_of_runs': 1,\n",
    "                 'particle_std': 1.0,\n",
    "                 'model_std': 1.0,\n",
    "                 'do_save': True,\n",
    "                 'plot_save': False,\n",
    "                 'agents_to_visualise': 1,\n",
    "                 'do_ani': False,\n",
    "                 'show_ani': False,\n",
    "                 'do_external_data': True,\n",
    "                 'resample_window': 100,\n",
    "                 'number_of_particles': 5000,\n",
    "                 'multi_step': False, # False for plot distance as function of pedestrian\n",
    "                 'do_resample': True, # True for experiments with D.A.\n",
    "                 'pf_method': 'sir', # ('sir' or 'hybrid') important if do_resample is True. \n",
    "                 'external_info': ['../GCT_final_real_data/', False, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run the Particle Filter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Particle Filter object\n",
    "pf = ParticleFilter(Model, model_params, filter_params)\n",
    "\n",
    "# Run the particle filter\n",
    "result = pf.step()\n",
    "pf.pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Use the appropriate method to generate the desired results.\n",
    "For the result bellow, we used the <b>get_distace_plot</b> method defined inside the <b>estimate_model</b> object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numiter = 1\n",
    "if pf.multi_step:\n",
    "    numiter = pf.resample_window\n",
    "\n",
    "pf.estimate_model.get_distace_plot(filter_params['external_info'][0]+'frame_', 1500, 3000, numiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIR Particle Filter\n",
    "\n",
    "In this experiment we used real data to perform the Data Assimilation using the SIR PF method. To do this, we use exactly the set of parameters presented above. The result is:\n",
    "\n",
    "![Experiment_SIR-PF_GCS](figs/Fig10.png)\n",
    "\n",
    "### More results\n",
    "\n",
    "You can find more results in this [`paper`](update with stationsim_gcs paper)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
